{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lecture 04\n",
    "\n",
    "1. Neural Networks\n",
    "2.\n",
    "3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Neural Networks\n",
    "\n",
    "Linear classifier는 선형 분류만 가능하므로 한계가 있다.\n",
    "\n",
    "![01.png](img/01.png)\n",
    "\n",
    "### 1) Multi-layers\n",
    "\n",
    "Linear score function : $ f=Wx $\n",
    "\n",
    "2-layer Nerual Network : $ f=W_2 max(0, W1x) $\n",
    "\n",
    "3-layer Nerual Network : $ f=W_3 max(0, W2 max(0,W1x)) $\n",
    "\n",
    "...\n",
    "\n",
    "이떄 max(0,z)과 같은 함수를 activation function 이라고 한다.\n",
    "activation function이 없으면, $f=W_2 W_1x = W_{1,2} x$ 와 같으므로 또다른 선형 함수가 된다.\n",
    "\n",
    "\n",
    "### 2) Activation functions\n",
    "\n",
    "activation function의 대표적인 종류는 다음과 같다.\n",
    "![02.png](img/02.png)\n",
    "\n",
    "\n",
    "### 3) Fully-connected layers\n",
    "\n",
    "여러개의 layer로 구성된 Nerual Network는 다음과 같이 표현된다.\n",
    "\n",
    "![03.png](img/03.png)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nerural Network\n",
    "## 코드는 나중에..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Backpropagation\n",
    "\n",
    "layer가 깊어지면 gradients를 계산하는데 힘이든다.\n",
    "\n",
    "모든 식을 수식화 하여 직점 $\\nabla_WL$를 계산하는 방법은 좋지 못한 방법이다. 매번 모델이 달라지면 다시 계산해야되며, 복잡한 모델일 수록 더욱 복잡해진다. 따라서 다음과 같은 방법을 이용한다.\n",
    "\n",
    "### 1) backpropagation\n",
    "\n",
    "![04.png](img/04.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
